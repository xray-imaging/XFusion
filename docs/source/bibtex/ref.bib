@article{Agiwal,
title = {Material flow visualization during friction stir welding using high-speed X-ray imaging},
journal = {Manufacturing Letters},
volume = {34},
pages = {62-66},
year = {2022},
issn = {2213-8463},
doi = {https://doi.org/10.1016/j.mfglet.2022.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S2213846322001894},
author = {Hemant Agiwal and Mohammad {Ali Ansari} and Daniel Franke and Patrick Faue and Samuel J. Clark and Kamel Fezzaa and Shiva Rudraraju and Michael Zinn and Frank E. Pfefferkorn},
keywords = {X-ray, Friction stir welding, Flow, Dynamics, Defect},
abstract = {This study employs high-speed X-ray imaging to capture the process dynamics during FSW in-situ, using a high-intensity X-ray beam to image a 2 mm × 2 mm area at 20,000 frames per second. The friction stir (FS) tool made of H13 tool steel with threads and 3-flats on the probe was used in an aluminum 6061-T6 workpiece. The process parameters employed result in a fully consolidated weldment without any observable sub-surface voids. The density changes captured by the high-intensity X-ray beam show the formation and filling of cavities in the wake of the tool three times per rotation.}
}

@ARTICLE{Chen,
  author={Chen, Lu and Ye, Mao and Ji, Luping and Li, Shuai and Guo, Hongwei},
  journal={IEEE Transactions on Broadcasting}, 
  title={Multi-Reference-Based Cross-Scale Feature Fusion for Compressed Video Super Resolution}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  keywords={Streaming media;Superresolution;Encoding;Video recording;Quality assessment;Video sequences;Video compression;Video compression;video quality enhancement;video super resolution;deep learning},
  doi={10.1109/TBC.2024.3407517}}

@article{Douissard,
doi = {10.1088/1748-0221/7/09/P09016},
url = {https://dx.doi.org/10.1088/1748-0221/7/09/P09016},
year = {2012},
month = {sep},
publisher = {},
volume = {7},
number = {09},
pages = {P09016},
author = {P -A Douissard and  A Cecilia and  X Rochet and  X Chapel and  T Martin and  T van de Kamp and  L Helfen and  T Baumbach and  L Luquot and  X Xiao and  J Meinhardt and  A Rack},
title = {A versatile indirect detector design for hard X-ray microimaging},
journal = {Journal of Instrumentation},
abstract = {Indirect X-ray detectors are of outstanding importance for high resolution imaging, especially at synchrotron light sources: while consisting mostly of components which are widely commercially available, they allow for a broad range of applications in terms of the X-ray energy employed, radiation dose to the detector, data acquisition rate and spatial resolving power. Frequently, an indirect detector consists of a thin-film single crystal scintillator and a high-resolution visible light microscope as well as a camera. In this article, a novel modular-based indirect design is introduced, which offers several advantages: it can be adapted for different cameras, i.e. different sensor sizes, and can be trimmed to work either with (quasi-)monochromatic illumination and the correspondingly lower absorbed dose or with intense white beam irradiation. In addition, it allows for a motorized quick exchange between different magnifications / spatial resolutions. Developed within the European project SCINTAX, it is now commercially available. The characteristics of the detector in its different configurations (i.e. for low dose or for high dose irradiation) as measured within the SCINTAX project will be outlined. Together with selected applications from materials research, non-destructive evaluation and life sciences they underline the potential of this design to make high resolution X-ray imaging widely available.}
}

@Article{Escauriza,
author={Escauriza, E. M.
and Duarte, J. P.
and Chapman, D. J.
and Rutherford, M. E.
and Farbaniec, L.
and Jonsson, J. C.
and Smith, L. C.
and Olbinado, M. P.
and Skidmore, J.
and Foster, P.
and Ringrose, T.
and Rack, A.
and Eakins, D. E.},
title={Collapse dynamics of spherical cavities in a solid under shock loading},
journal={Scientific Reports},
year={2020},
month={May},
day={21},
volume={10},
number={1},
pages={8455},
abstract={Extraordinary states of highly localised pressure and temperature can be generated upon the collapse of impulsively driven cavities. Direct observation of this phenomenon in solids has proved challenging, but recent advances in high-speed synchrotron radiography now permit the study of highly transient, subsurface events in real time. We present a study on the shock-induced collapse of spherical cavities in a solid polymethyl methacrylate medium, driven to shock states between 0.49 and 16.60 GPa. Utilising multi-MHz phase contrast radiography, extended sequences of the collapse process have been captured, revealing new details of interface motion, material failure and jet instability formation. Results reveal a rich array of collapse characteristics dominated by strength effects at low shock pressures and leading to a hydrodynamic response at the highest loading conditions.},
issn={2045-2322},
doi={10.1038/s41598-020-64669-y},
url={https://doi.org/10.1038/s41598-020-64669-y}
}

@BOOK{Hasinoff,
  title     = "Computer vision",
  editor    = "Ikeuchi, Katsushi",
  publisher = "Springer Nature",
  series    = "Computer Vision",
  edition   =  2,
  month     =  sep,
  year      =  2021,
  address   = "Cham, Switzerland",
  language  = "en"
}

@article{He,
title = {Multimodal fusion-based high-fidelity compressed ultrafast photography},
journal = {Optics and Lasers in Engineering},
volume = {181},
pages = {108363},
year = {2024},
issn = {0143-8166},
doi = {https://doi.org/10.1016/j.optlaseng.2024.108363},
url = {https://www.sciencedirect.com/science/article/pii/S0143816624003415},
author = {Yu He and Yunhua Yao and Yilin He and Chengzhi Jin and Zhengqi Huang and Mengdi Guo and Jiali Yao and Dalong Qi and Yuecheng Shen and Lianzhong Deng and Zhiyong Wang and Wei Zhao and Jinshou Tian and Yanhua Xue and Duan Luo and Zhenrong Sun and Shian Zhang},
keywords = {Ultrafast imaging, Compressed ultrafast photography, Image reconstruction},
abstract = {Featuring high frame rate and large sequence depth in a single shot, compressed ultrafast photography (CUP) has emerged as an outstanding tool for observing ultrafast phenomena, especially those unrepeatable or irreversible ones. However, the lower image quality in CUP due to high data compressive ratio has always been a tough issue, hampering its further applications in capturing the transient scenes with fine structural information. To overcome this disadvantage in CUP, here we report a multimodal fusion-based compressed ultrafast photography to achieve high-fidelity ultrafast imaging, termed MF-CUP. MF-CUP simultaneously records the dynamic scenes with three different imaging models, involving CUP, transient imaging and spatiotemporal integration imaging. Attributed to the joint acquisition of the dynamic scenes from different imaging models and the multimodal fusion image reconstruction algorithm enabled by untrained neural network, MF-CUP acquires the higher fidelity in both spatial and temporal domains compared with traditional CUP. Both the simulation and experimental results demonstrate that MF-CUP can effectively enhance the accuracy and quality of reconstructed images. Given this high-fidelity imaging ability of MF-CUP, it will provide a powerful tool for the detection of ultrafast dynamics with fine details.}
}

@article{Koch,
title = {Lens coupled scintillating screen-CCD X-ray area detector with a high detective quantum efficiency},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {348},
number = {2},
pages = {654-658},
year = {1994},
issn = {0168-9002},
doi = {https://doi.org/10.1016/0168-9002(94)90818-4},
url = {https://www.sciencedirect.com/science/article/pii/0168900294908184},
author = {Andreas Koch},
abstract = {An X-ray area detector consisting essentially of a scintillating screen, a fast objective and a cooled 1242 × 1152 slow scan CCD camera is described. A detective quantum efficiency (DQE) of > 0.3 for a planar field of view of Ø110 mm and photon energies between 10 and 20 keV is obtainable at integrated intensity levels above 108 eV/mm2/readout without any image intensification. At lower intensities the readout noise of the CCD camera (8 e−pixel) deteriorates the DQE. The spatial resolution of the detector is 100 μm (FWHM) and the dynamic range 104. The design easily allows the exchange of screens in order to optimize the detector at other photon energies. The performance of the detector will be discussed in terms of DQE, dynamic range, spatial resolution, spatial distortion and uniformity of response. The detector will be initially used for small angle scattering and diffraction experiments as part of the Microfocus Beamline at the European Synchrotron Radiation Facility (ESRF).}
}

@article{Kornienko,
author = {Vassily Kornienko and David Andersson and Mehdi Stiti and Jonas Ravelid and Simon Ek and Andreas Ehn and Edouard Berrocal and Elias Kristensson},
journal = {Photon. Res.},
keywords = {CCD cameras; Image sensors; Imaging systems; Laser ablation; Real time imaging; Streak cameras},
number = {7},
pages = {1712--1722},
publisher = {Optica Publishing Group},
title = {Simultaneous multiple time scale imaging for kHz\&\#x2013;MHz high-speed accelerometry},
volume = {10},
month = {Jul},
year = {2022},
url = {https://opg.optica.org/prj/abstract.cfm?URI=prj-10-7-1712},
doi = {10.1364/PRJ.451108},
abstract = {Fast transient events, such as the disintegration of liquid bodies or chemical reactions between radical species, involve various processes that may occur at different time scales. Currently, there are two alternatives for monitoring such events: burst- or high-speed imaging. Burst imaging at ultrahigh speeds (\&\#x223C;100\&\#x2009;\&\#x2009;MHz to THz) allows for the capture of nature\&\#x2019;s fastest processes but only for a narrowly confined period of time and at a repetition rate of \&\#x223C;10\&\#x2009;\&\#x2009;Hz. Monitoring long lasting, rapidly evolving transient events requires a significantly higher repetition rate, which is met by existing \&\#x223C;kHz to 1\&\#x2009;\&\#x2009;MHz high-speed imaging technology. However, the use of such systems eliminates the possibility to observe dynamics occurring on the sub-microsecond time scale. In this paper, we present a solution to this technological gap by combining multiplexed imaging with high-speed sensor technology, resulting in temporally resolved, high-spatial-resolution image series at two simultaneous time scales. We further demonstrate how the collection of such data opens up the tracking of rapidly evolving structures up to MHz burst rates over long durations, allowing, for the first time, to our knowledge, the extraction of acceleration fields acting upon the liquid bodies of an atomizing spray in two dimensions at kHz frame rates.},
}

@ARTICLE{Li,
  author={Li, Daoyu and Bian, Liheng and Zhang, Jun},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={High-Speed Large-Scale Imaging Using Frame Decomposition From Intrinsic Multiplexing of Motion}, 
  year={2022},
  volume={16},
  number={4},
  pages={700-712},
  keywords={Imaging;Cameras;Image coding;Multiplexing;Sensors;Image sensors;Spatial resolution;High-speed imaging;frame decomposition;intrinsic multiplexing of motion;affine motion modeling},
  doi={10.1109/JSTSP.2022.3164524}}

@INPROCEEDINGS{Lim,
  author={Lim, Bee and Son, Sanghyun and Kim, Heewon and Nah, Seungjun and Lee, Kyoung Mu},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Enhanced Deep Residual Networks for Single Image Super-Resolution}, 
  year={2017},
  volume={},
  number={},
  pages={1132-1140},
  keywords={Training;Image resolution;Computer architecture;Computational modeling;Signal resolution;Image reconstruction;Convolution},
  doi={10.1109/CVPRW.2017.151}}

@Article{Liu,
AUTHOR = {Hong, D. and Yao, J. and Wu, X. and Chanussot, J. and Zhu, X.},
TITLE = {SPATIAL-SPECTRAL MANIFOLD EMBEDDING OF HYPERSPECTRAL DATA},
JOURNAL = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
VOLUME = {XLIII-B3-2020},
YEAR = {2020},
PAGES = {423--428},
URL = {https://isprs-archives.copernicus.org/articles/XLIII-B3-2020/423/2020/},
DOI = {10.5194/isprs-archives-XLIII-B3-2020-423-2020}
}

@ARTICLE{Lu,
  author={Lu, Ming and Chen, Tong and Dai, Zhenyu and Wang, Dong and Ding, Dandan and Ma, Zhan},
  journal={IEEE Transactions on Multimedia}, 
  title={Decoder-Side Cross Resolution Synthesis for Video Compression Enhancement}, 
  year={2023},
  volume={25},
  number={},
  pages={2097-2110},
  keywords={Spatial resolution;Encoding;Streaming media;Video compression;Bit rate;Decoding;Standards;Video coding;cross resolution synthesis;super resolution;deep learning},
  doi={10.1109/TMM.2022.3142414}}

@article{Manin,
author = {Julien Manin and Scott A. Skeen and Lyle M. Pickett},
title = {{Performance comparison of state-of-the-art high-speed video cameras for scientific applications}},
volume = {57},
journal = {Optical Engineering},
number = {12},
publisher = {SPIE},
pages = {124105},
keywords = {high-speed imaging, camera characterization, scientific imaging, CMOS sensors, Cameras, Signal to noise ratio, Sensors, High speed cameras, Digital imaging, Light emitting diodes, Camera shutters, CMOS sensors, Imaging systems, Optical engineering},
year = {2018},
doi = {10.1117/1.OE.57.12.124105},
URL = {https://doi.org/10.1117/1.OE.57.12.124105}
}

@inproceedings{Miyauchi,
author = {K. Miyauchi and Tohru Takeda and K. Hanzawa and Y. Tochigi and S. Sakai and R. Kuroda and H. Tominaga and R. Hirose and K. Takubo and Y. Kondo and S. Sugawa},
title = {{Pixel structure with 10 nsec fully charge transfer time for the 20m frame per second burst CMOS image sensor}},
volume = {9022},
booktitle = {Image Sensors and Imaging Systems 2014},
editor = {Ralf Widenhorn and Antoine Dupret},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {902203},
keywords = {burst CMOS image sensor, ultra-high speed, pixel structure, fully charge transfer},
year = {2014},
doi = {10.1117/12.2042373},
URL = {https://doi.org/10.1117/12.2042373}
}

@InProceedings{Nah,
author = {Nah, Seungjun and Baik, Sungyong and Hong, Seokil and Moon, Gyeongsik and Son, Sanghyun and Timofte, Radu and Mu Lee, Kyoung},
title = {NTIRE 2019 Challenge on Video Deblurring and Super-Resolution: Dataset and Study},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2019}
}

@article{Nguyen,
  title={Imaging with an ultra-high-speed video camera operating at 20 Mfps for 300 kpixels},
  author={Hoang Dung Nguyen and Tomoo Okinaka and Yasuhide Takano and Kohsei Takehara and Vu Truong Son Dao and Takeharu Goji Etoh},
  journal={Mechanical Engineering Journal},
  volume={3},
  number={6},
  pages={16-00286-16-00286},
  year={2016},
  doi={10.1299/mej.16-00286}
}

@article{etoh2017theoretical,
  title={The theoretical highest frame rate of silicon image sensors},
  author={Etoh, Takeharu Goji and Nguyen, Anh Quang and Kamakura, Yoshinari and Shimonomura, Kazuhiro and Le, Thi Yen and Mori, Nobuya},
  journal={Sensors},
  volume={17},
  number={3},
  pages={483},
  year={2017},
  publisher={MDPI}
}

@article{bonse1996x,
  title={X-ray computed microtomography ($\mu$CT) using synchrotron radiation (SR)},
  author={Bonse, Ulrich and Busch, Frank},
  journal={Progress in biophysics and molecular biology},
  volume={65},
  number={1-2},
  pages={133--169},
  year={1996},
  publisher={Elsevier}
}

@article{hartmann1975high,
  title={High-resolution direct-display x-ray topography},
  author={Hartmann, W and Markewitz, G and Rettenmaier, U and Queisser, HJ},
  journal={Applied Physics Letters},
  volume={27},
  number={5},
  pages={308--309},
  year={1975},
  publisher={American Institute of Physics}
}

@article{Ren,
author = {Zhongshu Ren  and Lin Gao  and Samuel J. Clark  and Kamel Fezzaa  and Pavel Shevchenko  and Ann Choi  and Wes Everhart  and Anthony D. Rollett  and Lianyi Chen  and Tao Sun },
title = {Machine learning–aided real-time detection of keyhole pore generation in laser powder bed fusion},
journal = {Science},
volume = {379},
number = {6627},
pages = {89-94},
year = {2023},
doi = {10.1126/science.add4667},
URL = {https://www.science.org/doi/abs/10.1126/science.add4667},
eprint = {https://www.science.org/doi/pdf/10.1126/science.add4667},
abstract = {Porosity defects are currently a major factor that hinders the widespread adoption of laser-based metal additive manufacturing technologies. One common porosity occurs when an unstable vapor depression zone (keyhole) forms because of excess laser energy input. With simultaneous high-speed synchrotron x-ray imaging and thermal imaging, coupled with multiphysics simulations, we discovered two types of keyhole oscillation in laser powder bed fusion of Ti-6Al-4V. Amplifying this understanding with machine learning, we developed an approach for detecting the stochastic keyhole porosity generation events with submillisecond temporal resolution and near-perfect prediction rate. The highly accurate data labeling enabled by operando x-ray imaging allowed us to demonstrate a facile and practical way to adopt our approach in commercial systems. Laser fusion techniques build metal parts through a high-energy melting process that too often creates structural defects in the form of pores. Ren et al. used x-rays to track the formation of these pores while also making observations with a thermal imaging system. This setup allowed the authors to develop a high-accuracy method for detecting pore formation from that thermal signature with the help of a machine learning method. Implementing this sort of tracking of pore formation would help avoid building parts with high porosity that are more likely to fail. —BG Thermal imaging can detect pore formation during laser powder bed fusion, helping to ensure quality control.}}

@misc{shi,
      title={Machine Learning for Spatiotemporal Sequence Forecasting: A Survey}, 
      author={Xingjian Shi and Dit-Yan Yeung},
      year={2018},
      eprint={1808.06865},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1808.06865}, 
}

@InProceedings{Tian,
author = {Tian, Yapeng and Zhang, Yulun and Fu, Yun and Xu, Chenliang},
title = {TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@article{Wang:19,
  author       = {Xintao Wang and
                  Kelvin C. K. Chan and
                  Ke Yu and
                  Chao Dong and
                  Chen Change Loy},
  title        = {{EDVR:} Video Restoration with Enhanced Deformable Convolutional Networks},
  journal      = {CoRR},
  volume       = {abs/1905.02716},
  year         = {2019},
  url          = {http://arxiv.org/abs/1905.02716},
  eprinttype    = {arXiv},
  eprint       = {1905.02716},
  timestamp    = {Mon, 27 May 2019 13:15:00 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1905-02716.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{Wang:04,
  author={Zhou Wang and Bovik, A.C. and Sheikh, H.R. and Simoncelli, E.P.},
  journal={IEEE Transactions on Image Processing}, 
  title={Image quality assessment: from error visibility to structural similarity}, 
  year={2004},
  volume={13},
  number={4},
  pages={600-612},
  keywords={Image quality;Humans;Transform coding;Visual system;Visual perception;Data mining;Layout;Quality assessment;Degradation;Indexes},
  doi={10.1109/TIP.2003.819861}}

@INPROCEEDINGS{Wu,
  author={Wu, Ziling and Bicer, Tekin and Liu, Zhengchun and De Andrade, Vincent and Zhu, Yunhui and Foster, Ian T.},
  booktitle={2020 IEEE/ACM Workshop on Machine Learning in High Performance Computing Environments (MLHPC) and Workshop on Artificial Intelligence and Machine Learning for Scientific Applications (AI4S)}, 
  title={Deep Learning-based Low-dose Tomography Reconstruction with Hybrid-dose Measurements}, 
  year={2020},
  volume={},
  number={},
  pages={88-95},
  keywords={Learning systems;Conferences;Noise reduction;Machine learning;Reconstruction algorithms;Noise measurement;Spatial resolution;low-dose tomography;image reconstruction;hybrid-dose measurement;projection denoising;deep learning},
  doi={10.1109/MLHPCAI4S51975.2020.00017}}

@ARTICLE{Xiao,
  author={Xiao, Yi and Yuan, Qiangqiang and Jiang, Kui and He, Jiang and Lin, Chia-Wen and Zhang, Liangpei},
  journal={IEEE Transactions on Image Processing}, 
  title={TTST: A Top-k Token Selective Transformer for Remote Sensing Image Super-Resolution}, 
  year={2024},
  volume={33},
  number={},
  pages={738-752},
  keywords={Transformers;Remote sensing;Task analysis;Kernel;Superresolution;Convolution;Interference;Remote sensing image;super-resolution;sparse transformer;selective attention},
  doi={10.1109/TIP.2023.3349004}}


@Article{xue2017bayesian,
AUTHOR = {Xue, Jie and Leung, Yee and Fung, Tung},
TITLE = {A Bayesian Data Fusion Approach to Spatio-Temporal Fusion of Remotely Sensed Images},
JOURNAL = {Remote Sensing},
VOLUME = {9},
YEAR = {2017},
NUMBER = {12},
ARTICLE-NUMBER = {1310},
URL = {https://www.mdpi.com/2072-4292/9/12/1310},
ISSN = {2072-4292},
ABSTRACT = {Remote sensing provides rich sources of data for the monitoring of land surface dynamics. However, single-sensor systems are constrained from providing spatially high-resolution images with high revisit frequency due to the inherent sensor design limitation. To obtain images high in both spatial and temporal resolutions, a number of image fusion algorithms, such as spatial and temporal adaptive reflectance fusion model (STARFM) and enhanced STARFM (ESTARFM), have been recently developed. To capitalize on information available in a fusion process, we propose a Bayesian data fusion approach that incorporates the temporal correlation information in the image time series and casts the fusion problem as an estimation problem in which the fused image is obtained by the Maximum A Posterior (MAP) estimator. The proposed approach provides a formal framework for the fusion of remotely sensed images with a rigorous statistical basis; it imposes no requirements on the number of input image pairs; and it is suitable for heterogeneous landscapes. The approach is empirically tested with both simulated and real-life acquired Landsat and Moderate Resolution Imaging Spectroradiometer (MODIS) images. Experimental results demonstrate that the proposed method outperforms STARFM and ESTARFM, especially for heterogeneous landscapes. It produces surface reflectances highly correlated with those of the reference Landsat images. It gives spatio-temporal fusion of remotely sensed images a solid theoretical and empirical foundation that may be extended to solve more complicated image fusion problems.},
DOI = {10.3390/rs9121310}
}

@article{Zhang,
  author       = {Hongyan Zhang and
                  Yiyao Song and
                  Chang Han and
                  Liangpei Zhang},
  title        = {Remote Sensing Image Spatiotemporal Fusion Using a Generative Adversarial
                  Network},
  journal      = {{IEEE} Trans. Geosci. Remote. Sens.},
  volume       = {59},
  number       = {5},
  pages        = {4273--4286},
  year         = {2021},
  url          = {https://doi.org/10.1109/TGRS.2020.3010530},
  doi          = {10.1109/TGRS.2020.3010530},
  timestamp    = {Fri, 03 Feb 2023 10:27:08 +0100},
  biburl       = {https://dblp.org/rec/journals/tgrs/ZhangSHZ21.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{sugawa2013ultra,
  title={Ultra-high speed video imaging technologies},
  author={Sugawa, Shigetoshi},
  booktitle={ITE Technical Report 37.19},
  pages={9--14},
  year={2013},
  organization={The Institute of Image Information and Television Engineers}
}

@article{tochigi2012global,
  title={A global-shutter CMOS image sensor with readout speed of 1-Tpixel/s burst and 780-Mpixel/s continuous},
  author={Tochigi, Yasuhisa and Hanzawa, Katsuhiko and Kato, Yuri and Kuroda, Rihito and Mutoh, Hideki and Hirose, Ryuta and Tominaga, Hideki and Takubo, Kenji and Kondo, Yasushi and Sugawa, Shigetoshi},
  journal={IEEE Journal of Solid-State Circuits},
  volume={48},
  number={1},
  pages={329--338},
  year={2012},
  publisher={IEEE}
}

@article{ma2024pretraining,
  title={Pretraining a foundation model for generalizable fluorescence microscopy-based image restoration},
  author={Ma, Chenxi and Tan, Weimin and He, Ruian and Yan, Bo},
  journal={Nature Methods},
  pages={1--10},
  year={2024},
  publisher={Nature Publishing Group US New York}
}

@article{luo2012gas,
  title={Gas gun shock experiments with single-pulse x-ray phase contrast imaging and diffraction at the Advanced Photon Source},
  author={Luo, SN and Jensen, BJ and Hooks, DE and Fezzaa, K and Ramos, KJ and Yeager, JD and Kwiatkowski, K and Shimada, T},
  journal={Review of Scientific Instruments},
  volume={83},
  number={7},
  year={2012},
  publisher={AIP Publishing}
}

@article{Ramos,
doi = {10.1088/1742-6596/500/14/142028},
url = {https://dx.doi.org/10.1088/1742-6596/500/14/142028},
year = {2014},
month = {may},
publisher = {},
volume = {500},
number = {14},
pages = {142028},
author = {K J Ramos and B J Jensen and A J Iverson and J D Yeager and C A Carlson and D S Montgomery and D G Thompson and K Fezzaa and D E Hooks},
title = {In situ investigation of the dynamic response of energetic materials using IMPULSE at the Advanced Photon Source},
journal = {Journal of Physics: Conference Series},
abstract = {The mechanical and chemical response of energetic materials is controlled by a convolution of deformation mechanisms that span length scales and evolve during impact. Traditional methods use continuum measurements to infer the microstructural response whereas advances in synchrotron capabilities and diagnostics are providing new, unique opportunities to interrogate materials in real time and in situ. Experiments have been performed on a new gas-gun system (IMPact system for Ultrafast Synchrotron Experiments) using single X-ray bunch phase contrast imaging (PCI) and Laue diffraction at the Advanced Photon Source (APS). The low absorption of molecular materials maximizes x-ray beam penetration, allowing measurements in transmission using the brilliance currently available at APS Sector 32. The transmission geometry makes it possible to observe both average lattice response and spatially heterogeneous, continuum response (1-4 um spatial resolution over ~2 × 2 mm area, 80 ps exposure, 153 ns frame-rate) in energetic materials ranging from single crystals to plastic-bonded composites. The current work describes our progress developing and using these diagnostics to observe deformation mechanisms relevant to explosives and the first experiments performed with explosives on IMPULSE at APS.}
}

@article{Parab,
author = "Parab, Niranjan D. and Zhao, Cang and Cunningham, Ross and Escano, Luis I. and Fezzaa, Kamel and Everhart, Wes and Rollett, Anthony D. and Chen, Lianyi and Sun, Tao",
title = "{Ultrafast X-ray imaging of laser{--}metal additive manufacturing processes}",
journal = "Journal of Synchrotron Radiation",
year = "2018",
volume = "25",
number = "5",
pages = "1467--1477",
month = "Sep",
doi = {10.1107/S1600577518009554},
url = {https://doi.org/10.1107/S1600577518009554},
abstract = {The high-speed synchrotron X-ray imaging technique was synchronized with a custom-built laser-melting setup to capture the dynamics of laser powder-bed fusion processes {\it in situ}. Various significant phenomena, including vapor-depression and melt-pool dynamics and powder-spatter ejection, were captured with high spatial and temporal resolution. Imaging frame rates of up to 10MHz were used to capture the rapid changes in these highly dynamic phenomena. At the same time, relatively slow frame rates were employed to capture large-scale changes during the process. This experimental platform will be vital in the further understanding of laser additive manufacturing processes and will be particularly helpful in guiding efforts to reduce or eliminate microstructural defects in additively manufactured parts.},
keywords = {X-ray imaging, laser powder-bed fusion, particle ejection, melt pools, vapor depressions, additive manufacturing.}
}

@online{OpenCV,
  author = {OpenCV},
  year = 2024,
  url = {https://opencv.org/},
  urldate = {2024-08-12}
}

@misc{basicsr,
  author =       {Xintao Wang and Liangbin Xie and Ke Yu and Kelvin C.K. Chan and Chen Change Loy and Chao Dong},
  title =        {{BasicSR}: Open Source Image and Video Restoration Toolbox},
  howpublished = {\url{https://github.com/XPixelGroup/BasicSR}},
  year =         {2022}
}

@article{DeCarlo,
doi = {10.1088/1361-6501/aa9c19},
url = {https://dx.doi.org/10.1088/1361-6501/aa9c19},
year = {2018},
month = {feb},
publisher = {IOP Publishing},
volume = {29},
number = {3},
pages = {034004},
author = {Francesco De Carlo and Doğa Gürsoy and Daniel J Ching and K Joost Batenburg and Wolfgang Ludwig and Lucia Mancini and Federica Marone and Rajmund Mokso and Daniël M Pelt and Jan Sijbers and Mark Rivers},
title = {TomoBank: a tomographic data repository for computational x-ray science},
journal = {Measurement Science and Technology},
}

@misc{XradFusionData, 
 title={XradFusion Datasets}, 
 url={\url{https://tomobank.readthedocs.io/en/latest/source/data/docs.data.radio.html#xradfusion}}, 
 journal={readthedocs}, 
 author={Tang, Songyuan}, 
 year={2024}
} 

@inproceedings{peters2015precision,
  title={Precision of FLEET velocimetry using high-speed CMOS camera systems},
  author={Peters, Christopher J and Danehy, Paul M and Bathel, Brett F and Jiang, Naibo and Calvert, Nathan and Miles, Richard B},
  booktitle={31st AIAA Aerodynamic Measurement Technology and Ground Testing Conference},
  pages={2565},
  year={2015}
}

@article{xue2019video,
  title={Video enhancement with task-oriented flow},
  author={Xue, Tianfan and Chen, Baian and Wu, Jiajun and Wei, Donglai and Freeman, William T},
  journal={International Journal of Computer Vision},
  volume={127},
  pages={1106--1125},
  year={2019},
  publisher={Springer}
}

@inproceedings{werlberger2011optical,
  title={Optical flow guided TV-L 1 video interpolation and restoration},
  author={Werlberger, Manuel and Pock, Thomas and Unger, Markus and Bischof, Horst},
  booktitle={Energy Minimization Methods in Computer Vision and Pattern Recognition: 8th International Conference, EMMCVPR 2011, St. Petersburg, Russia, July 25-27, 2011. Proceedings 8},
  pages={273--286},
  year={2011},
  organization={Springer}
}

@article{fransens2007optical,
  title={Optical flow based super-resolution: A probabilistic approach},
  author={Fransens, Rik and Strecha, Christoph and Van Gool, Luc},
  journal={Computer vision and image understanding},
  volume={106},
  number={1},
  pages={106--115},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{caballero2017real,
  title={Real-time video super-resolution with spatio-temporal networks and motion compensation},
  author={Caballero, Jose and Ledig, Christian and Aitken, Andrew and Acosta, Alejandro and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4778--4787},
  year={2017}
}

@article{wang2020deep,
  title={Deep video super-resolution using HR optical flow estimation},
  author={Wang, Longguang and Guo, Yulan and Liu, Li and Lin, Zaiping and Deng, Xinpu and An, Wei},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={4323--4336},
  year={2020},
  publisher={IEEE}
}

@inproceedings{dai2017deformable,
  title={Deformable convolutional networks},
  author={Dai, Jifeng and Qi, Haozhi and Xiong, Yuwen and Li, Yi and Zhang, Guodong and Hu, Han and Wei, Yichen},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={764--773},
  year={2017}
}

@inproceedings{zhu2019deformable,
  title={Deformable convnets v2: More deformable, better results},
  author={Zhu, Xizhou and Hu, Han and Lin, Stephen and Dai, Jifeng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={9308--9316},
  year={2019}
}

@article{benmore2022advancing,
  title={Advancing AI/ML at the Advanced Photon Source},
  author={Benmore, Chris and Bicer, Tekin and Chan, Maria KY and Di, Zichao and G{\"u}rsoy, Dog˘ a and Hwang, Inhui and Kuklev, Nikita and Lin, Dergan and Liu, Zhengchun and Lobach, Ihar and others},
  journal={Synchrotron Radiation News},
  volume={35},
  number={4},
  pages={28--35},
  year={2022},
  publisher={Taylor \& Francis}
}

@inproceedings{liu2019deep,
  title={Deep learning accelerated light source experiments},
  author={Liu, Zhengchun and Bicer, Tekin and Kettimuthu, Rajkumar and Foster, Ian},
  booktitle={2019 IEEE/ACM Third Workshop on Deep Learning on Supercomputers (DLS)},
  pages={20--28},
  year={2019},
  organization={IEEE}
}

@article{liu2020tomogan,
  title={TomoGAN: low-dose synchrotron x-ray tomography with generative adversarial networks: discussion},
  author={Liu, Zhengchun and Bicer, Tekin and Kettimuthu, Rajkumar and Gursoy, Doga and De Carlo, Francesco and Foster, Ian},
  journal={JOSA A},
  volume={37},
  number={3},
  pages={422--434},
  year={2020},
  publisher={Optica Publishing Group}
}